# Supported models

This plugin uses GGUF format models. Download a model and place it to a desired path.  
The following models have been tested to work.

- [llama-3 7B](https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/blob/main/Meta-Llama-3-8B-Instruct.Q4_K_S.gguf)
- [Phi-3-medium](https://huggingface.co/mmnga/Phi-3-medium-128k-instruct-gguf/blob/main/Phi-3-medium-128k-instruct-Q4_K_S.gguf)
- [Gemma 7B](https://huggingface.co/mmnga/gemma-7b-it-gguf/blob/main/gemma-7b-it-q8_0.gguf)
- [Mistral 7B](https://huggingface.co/TheBloke/Mistral-7B-v0.1-GGUF/blob/main/mistral-7b-v0.1.Q4_K_S.gguf)

(Japanese model)

- [ArrowPro 7B KUJIRA](https://huggingface.co/mmnga/DataPilot-ArrowPro-7B-KUJIRA-gguf/blob/main/DataPilot-ArrowPro-7B-KUJIRA-Q4_K_S.gguf)