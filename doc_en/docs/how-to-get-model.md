# Supported models

This plugin uses GGUF format models. Download a model and place it to a desired path.  
The following models have been tested to work.

- [Llama 3 8B](https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/blob/main/Meta-Llama-3-8B-Instruct.Q4_K_S.gguf)
- [Phi-3 Medium](https://huggingface.co/mmnga/Phi-3-medium-128k-instruct-gguf/blob/main/Phi-3-medium-128k-instruct-Q4_K_S.gguf)
- [Gemma 7B](https://huggingface.co/mmnga/gemma-7b-it-gguf/blob/main/gemma-7b-it-q8_0.gguf)
- [Gemma-2 9B](https://huggingface.co/bartowski/gemma-2-9b-it-GGUF/blob/main/gemma-2-9b-it-Q4_K_S.gguf)
- [Mistral 7B](https://huggingface.co/TheBloke/Mistral-7B-v0.1-GGUF/blob/main/mistral-7b-v0.1.Q4_K_S.gguf)

(Japanese model)

- [ArrowPro 7B RobinHood](https://huggingface.co/mmnga/DataPilot-ArrowPro-7B-RobinHood-gguf/blob/main/DataPilot-ArrowPro-7B-RobinHood-IQ4_XS.gguf)
- [ArrowPro 7B KUJIRA](https://huggingface.co/mmnga/DataPilot-ArrowPro-7B-KUJIRA-gguf/blob/main/DataPilot-ArrowPro-7B-KUJIRA-IQ4_XS.gguf)
- [ELYZA JP 8B](https://huggingface.co/elyza/Llama-3-ELYZA-JP-8B-GGUF/blob/main/Llama-3-ELYZA-JP-8B-q4_k_m.gguf)